# 本部分主要是介绍吴恩达课程中，如何使用python来搭建两层神经网络
## 普通的逻辑回归其预测的结果如下：
Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints)<br>
![](https://https://github.com/Anosy/Ng_DL/blob/master/1_3_one_hidden_layer/logistic.png)<br>
## 两层神经网络运行的结果如下：
Cost after iteration 0: 1.127380<br>
Cost after iteration 1000: 0.818943<br>
Cost after iteration 2000: 0.635655<br>
Cost after iteration 3000: 0.578281<br>
Cost after iteration 4000: 0.548331<br>
Cost after iteration 5000: 0.527887<br>
Cost after iteration 6000: 0.511518<br>
Cost after iteration 7000: 0.497573<br>
Cost after iteration 8000: 0.485563<br>
Cost after iteration 9000: 0.475241<br>
Accuracy: 84%<br>
![](https://https://github.com/Anosy/Ng_DL/blob/master/1_3_one_hidden_layer/1_hidden_NN.png)<br>
## 本部分还添加上了简单的tensorflow实现版本，效果如下：
迭代2000次，损失值降低为0.637905<br>
迭代4000次，损失值降低为0.619604<br>
迭代6000次，损失值降低为0.512578<br>
迭代8000次，损失值降低为0.451549<br>
迭代10000次，损失值降低为0.418049<br>
迭代12000次，损失值降低为0.396835<br>
迭代14000次，损失值降低为0.382289<br>
迭代16000次，损失值降低为0.371699<br>
迭代18000次，损失值降低为0.363612<br>
迭代20000次，损失值降低为0.3572<br>
训练集的精确度为86.75%<br>

